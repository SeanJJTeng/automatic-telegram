{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to RNN Workshop",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGTnInyEharX",
        "colab_type": "text"
      },
      "source": [
        "# Before you start\n",
        "1. **Don't edit this file, make a copy first:**\n",
        "  * Click on File -> Save a copy in Drive\n",
        "\n",
        "2. Also do the following:\n",
        "  * Click on Runtime -> Change runtime type -> Make sure hardware accelerator is set to GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVSz5_Hn5jv4",
        "colab_type": "text"
      },
      "source": [
        "# Goal of this notebook\n",
        "\n",
        "- Intro and example to working with RNNs in Pytorch through a sentiment analysis problem (a type of NLP)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZueWb5ZRDeyT",
        "colab_type": "text"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlJ_aMz20rxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import bz2\n",
        "import re\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data as tdata"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArN22HR9W-RC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "356ef167-8abd-4a90-9dad-c1d869e41326"
      },
      "source": [
        "# Place kaggle.json where it needs to be\n",
        "\n",
        "user = \"xantha9\"\n",
        "key = \"807bb77939717caa78d1b7d98701b569\"\n",
        "# Create directory\n",
        "if '.kaggle' not in os.listdir('/content'):\n",
        "    !mkdir /root/.kaggle\n",
        "# Create file and write in kaggle user information\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "!chmod 666 /root/.kaggle/kaggle.json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "    f.write('{\"username\":\"%s\",\"key\":\"%s\"}' % (user, key))\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# Download kaggle data\n",
        "!pip install kaggle\n",
        "# Download data\n",
        "!kaggle datasets download -d bittlingmayer/amazonreviews"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Downloading amazonreviews.zip to /content\n",
            " 98% 481M/493M [00:20<00:00, 19.8MB/s]\n",
            "100% 493M/493M [00:20<00:00, 25.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hepIxB_VKggb",
        "colab_type": "text"
      },
      "source": [
        "We are working with the Amazon review dataset, notice the same (data,label) concept is used to process our data.\n",
        "\n",
        "Much like an image classification example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV-wH17bzqyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_zip():\n",
        "  with zipfile.ZipFile('/content/amazonreviews.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')\n",
        "    print(\"Zip file extracted\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV-n0yrZ9kq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92e769ab-2076-40de-aac2-a7817a24793a"
      },
      "source": [
        "unzip = True\n",
        "\n",
        "if unzip:\n",
        "  extract_zip()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zip file extracted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tHfx_Nl3get",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_text_labels(file):\n",
        "  labels = []\n",
        "  texts = []\n",
        "  for line in bz2.BZ2File(file):\n",
        "    line = line.decode('utf-8')\n",
        "    labels.append(int(line[9]) - 1)\n",
        "    texts.append(line[10:].strip())\n",
        "  return np.array(labels), texts"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyjdn-TcPSDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NON_ALPHANUM = re.compile(r'[\\W]')\n",
        "NON_ASCII = re.compile(r'[^a-z\\s]')\n",
        "\n",
        "def normalize_text(text):\n",
        "  normalized_texts = []\n",
        "  for line in text:\n",
        "    line = line.lower()\n",
        "    no_punctuation = NON_ALPHANUM.sub(r' ', line)\n",
        "    no_non_ascii = NON_ASCII.sub(r'', no_punctuation)\n",
        "    normalized_texts.append(no_non_ascii)\n",
        "  return normalized_texts"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj1tYsOjGXCB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53fa0ddc-0048-4868-bbcd-e6d185dedcb5"
      },
      "source": [
        "train_labels, train_text = get_text_labels('/content/test.ft.txt.bz2')\n",
        "\n",
        "train_text = train_text[:5000]\n",
        "train_labels = train_labels[:5000]\n",
        "\n",
        "print(len(train_text)) #3.6M rows of data, takes awhile"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-RRD1nxJOaP",
        "colab_type": "text"
      },
      "source": [
        "##Making sense of the data\n",
        "We see the sentiment label (0 for poor review, 1 for good) matched with its review\n",
        "\n",
        "There are non-Alphanumeric chars and upper/lower cases to clean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c26lEA0N9OTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "17df14da-ef2d-47ae-e5ea-18e8f01769b5"
      },
      "source": [
        "for i in range(3):\n",
        "  print(train_labels[i], train_text[i])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I'm in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life's hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"\n",
            "1 One of the best game music soundtracks - for a game I didn't really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\n",
            "0 Batteries died within a year ...: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq6otJ42EzVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f3298f8a-0760-4786-9ac4-b236521e3121"
      },
      "source": [
        "train_text = normalize_text(train_text)\n",
        "\n",
        "print(train_text[0])\n",
        "print(train_text[60])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "great cd  my lovely pat has one of the great voices of her generation  i have listened to this cd for years and i still love it  when i m in a good mood it makes me feel better  a bad mood just evaporates like sugar in the rain  this cd just oozes life  vocals are jusat stuunning and lyrics just kill  one of life s hidden gems  this is a desert isle cd in my book  why she never made it big is just beyond me  everytime i play this  no matter black  white  young  old  male  female everybody says one thing  who was that singing   \n",
            "simply awesome   this was only my first cornwell novel and i m hooked  in the past few months i have managed to collect all of her books and i can t wait to dive into them  this summer will be a suspensful one for scarpetta and i \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuVqiEt0Gb81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TOP_COMMON = 5000\n",
        "\n",
        "text_str = ' '.join(train_text)\n",
        "\n",
        "#Counting the # of times a given word shows up in our reviews and sorting them by most common first\n",
        "words = text_str.split()\n",
        "\n",
        "word_count = Counter(words)\n",
        "\n",
        "sorted_common = word_count.most_common(TOP_COMMON)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw15UUTFHa2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "453007c2-6f9d-49df-ca2d-78a63579b3c0"
      },
      "source": [
        "print(len(sorted_common))\n",
        "\n",
        "print(sorted_common[4999])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "('valve', 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZizp8_HAf7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2504db48-c4df-4a02-fe86-ad1d6b71afbd"
      },
      "source": [
        "#Ordering the most common words & storing into a look up table\n",
        "#0 will be the padding, 1 will be the missing words that are not in our most common\n",
        "word2idx = {w:i+2 for i, (w,c) in enumerate(sorted_common)}\n",
        "\n",
        "print(next(iter(word2idx)))\n",
        "print(word2idx[next(iter(word2idx))])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy3UhaYSJkrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "common_words = [item[0] for item in sorted_common]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5FBiFhNNJa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenizing our reviews into numbers based on the look up table\n",
        "train_token = []\n",
        "for line in train_text:\n",
        "  temp_array = []\n",
        "  token = [word2idx[word] if word in common_words else 1 for word in line.split()]\n",
        "  train_token.append(token)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOH2PV7rOM3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3bc3f7e0-72a2-46c5-89a9-41034859fe13"
      },
      "source": [
        "#Checking our tokens actually match the words using first and last number of the 1st list (1st review)\n",
        "print(word2idx['great'])\n",
        "print(word2idx['singing'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35\n",
            "814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5ZfCWj--xxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "46bcf65f-c4f0-44d1-d9f4-c9e91d6394a6"
      },
      "source": [
        "reviews_len = [len(x) for x in train_token]\n",
        "pd.Series(reviews_len).hist()\n",
        "plt.show()\n",
        "\n",
        "pd.Series(reviews_len).describe()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARH0lEQVR4nO3df4wcZ33H8fe3NgkhBjs/0CmyXc6UlCqKVbBPkIofOmPUJjbFaQsoKAKburKqBhoaI2KKVPinktMqpCAhkFsjTJXiQADFItBCja+IP+I2DiZ2YtJcggFbxmnSYHAIBZdv/9jH6eW4vVv7dm+Gx++XdLqZZ2ZnPze7/tzs3O44MhNJUl1+rekAkqT+s9wlqUKWuyRVyHKXpApZ7pJUoflNBwC49NJLc3h4uOkYz3jqqae48MILm47RVZvztTkbtDtfm7OB+WZjUNn27dv3eGa+cMqFmdn418qVK7NN9uzZ03SEabU5X5uzZbY7X5uzZZpvNgaVDbg3u/Sqp2UkqUKWuyRVyHKXpApZ7pJUIctdkipkuUtShSx3SaqQ5S5JFbLcJalCrbj8wK+q4S13N3K/n7y6nR+xltQeHrlLUoUsd0mqkOUuSRWy3CWpQpa7JFXIcpekClnuklQhy12SKmS5S1KFLHdJqpDlLkkVstwlqUKWuyRVyHKXpApZ7pJUIctdkipkuUtShSx3SaqQ5S5JFbLcJalCPZV7RPxFRDwQEQcj4tMR8dyIWBYReyNiPCLuiIjzyrrnl/nxsnx4kD+AJOmXzVjuEbEY+HNgJDOvBOYB1wG3ALdl5kuAJ4GN5SYbgSfL+G1lPUnSHOr1tMx84IKImA88DzgGvA64syzfAVxbpteVecry1RER/YkrSepFZObMK0XcCPw18DTwFeBG4J5ydE5ELAW+nJlXRsRB4OrMPFKWPQK8MjMfn7TNTcAmgKGhoZU7d+7s3081SydPnmTBggUzrnfg6Ik5SPPLli2c11O+JvS675rS5nxtzgbmm41BZVu1atW+zByZatn8mW4cERfRORpfBvwQ+Cxw9WxDZeY2YBvAyMhIjo6OznaTfTM2NkYveTZsuXvwYaawefkpbv3GU43c9+Gta6dd3uu+a0qb87U5G5hvNprI1stpmdcD38nM/8rMnwOfB14FLCqnaQCWAEfL9FFgKUBZvhB4oq+pJUnT6qXcvwdcFRHPK+fOVwMPAnuAN5V11gN3leldZZ6y/GvZy7kfSVLfzFjumbmXzh9G7wMOlNtsA24GboqIceASYHu5yXbgkjJ+E7BlALklSdOY8Zw7QGZ+APjApOFHgVdMse5PgTfPPpok6Wz5CVVJqpDlLkkVstwlqUKWuyRVyHKXpApZ7pJUIctdkipkuUtShSx3SaqQ5S5JFbLcJalClrskVchyl6QKWe6SVCHLXZIqZLlLUoUsd0mqkOUuSRWy3CWpQpa7JFWop/8gWzpteMvd0y7fvPwUG2ZY52wc3rq279uUauaRuyRVyHKXpApZ7pJUIctdkipkuUtShSx3SaqQ5S5JFbLcJalClrskVchyl6QK/cpffmCmj8OfjUF9hF6S5opH7pJUIctdkipkuUtShSx3SaqQ5S5JFeqp3CNiUUTcGRHfjohDEfE7EXFxRHw1Ih4u3y8q60ZEfCQixiPi/ohYMdgfQZI0Wa9H7h8G/jkzfwv4beAQsAXYnZmXA7vLPMA1wOXlaxPwsb4mliTNaMZyj4iFwGuB7QCZ+bPM/CGwDthRVtsBXFum1wGfyo57gEURcVnfk0uSuorMnH6FiJcB24AH6Ry17wNuBI5m5qKyTgBPZuaiiPgisDUzv1GW7QZuzsx7J213E50je4aGhlbu3LnzrH6AA0dPnNXtpjN0ARx/uu+b7Zs25xtUtuWLF/ZlOydPnmTBggV92Va/tTkbmG82BpVt1apV+zJzZKplvXxCdT6wAnhXZu6NiA/z/6dgAMjMjIjpf0tMkpnb6PzSYGRkJEdHR8/k5s8YxCdJNy8/xa0H2vvh3TbnG1S2w9eP9mU7Y2NjnO1zbdDanA3MNxtNZOvlnPsR4Ehm7i3zd9Ip++OnT7eU74+V5UeBpRNuv6SMSZLmyIzlnpk/AL4fES8tQ6vpnKLZBawvY+uBu8r0LuDt5V0zVwEnMvNYf2NLkqbT6+vndwG3R8R5wKPAO+j8YvhMRGwEvgu8paz7JWANMA78pKwrSZpDPZV7Zu4Hpjppv3qKdRO4YZa5JEmz4CdUJalC7XzLhTRJv67bf6bX6j+8dW1f7leaax65S1KFLHdJqpDlLkkVstwlqUKWuyRVyHKXpApZ7pJUIctdkipkuUtShSx3SaqQ5S5JFbLcJalClrskVchyl6QKWe6SVCHLXZIqZLlLUoUsd0mqkOUuSRWy3CWpQpa7JFXIcpekClnuklQhy12SKjS/6QBSmw1vuXvO7mvz8lNsmHB/h7eunbP7Vn08cpekClnuklQhy12SKmS5S1KFLHdJqpDlLkkVstwlqUKWuyRVyHKXpAr1XO4RMS8ivhkRXyzzyyJib0SMR8QdEXFeGT+/zI+X5cODiS5J6uZMjtxvBA5NmL8FuC0zXwI8CWws4xuBJ8v4bWU9SdIc6qncI2IJsBb4hzIfwOuAO8sqO4Bry/S6Mk9ZvrqsL0maI70euf8d8F7gF2X+EuCHmXmqzB8BFpfpxcD3AcryE2V9SdIcicycfoWINwBrMvPPImIUeA+wAbinnHohIpYCX87MKyPiIHB1Zh4pyx4BXpmZj0/a7iZgE8DQ0NDKnTt3ntUPcODoibO63XSGLoDjT/d9s33T5nxtzgbtzjc52/LFC5sLM4WTJ0+yYMGCpmN01eZ8g8q2atWqfZk5MtWyXi75+yrgjRGxBngu8ALgw8CiiJhfjs6XAEfL+keBpcCRiJgPLASemLzRzNwGbAMYGRnJ0dHRM/qhTtswgEuybl5+ilsPtPdqyG3O1+Zs0O58k7Mdvn60uTBTGBsb42z/nc6FNudrItuMp2Uy832ZuSQzh4HrgK9l5vXAHuBNZbX1wF1leleZpyz/Ws708kCS1FezeZ/7zcBNETFO55z69jK+HbikjN8EbJldREnSmTqj16eZOQaMlelHgVdMsc5PgTf3IZsk6Sz5CVVJqpDlLkkVstwlqUKWuyRVqJ1v+JXE8AA+w9GLw1vXNnK/6i+P3CWpQpa7JFXIcpekClnuklQhy12SKmS5S1KFLHdJqpDlLkkVstwlqUKWuyRVyHKXpApZ7pJUIctdkipkuUtShSx3SaqQ13OX9CzdriO/efkpNgz4GvNeS75/PHKXpApZ7pJUIctdkipkuUtShSx3SaqQ5S5JFbLcJalClrskVchyl6QKWe6SVCHLXZIqZLlLUoW8cJik1uh20bJezObCZjVesMwjd0mqkOUuSRWy3CWpQjOWe0QsjYg9EfFgRDwQETeW8Ysj4qsR8XD5flEZj4j4SESMR8T9EbFi0D+EJOnZejlyPwVszswrgKuAGyLiCmALsDszLwd2l3mAa4DLy9cm4GN9Ty1JmtaM5Z6ZxzLzvjL9Y+AQsBhYB+woq+0Ari3T64BPZcc9wKKIuKzvySVJXUVm9r5yxDDwdeBK4HuZuaiMB/BkZi6KiC8CWzPzG2XZbuDmzLx30rY20TmyZ2hoaOXOnTvP6gc4cPTEWd1uOkMXwPGn+77ZvmlzvjZng3bna3M2qDvf8sUL+xtmkpMnT7JgwYK+b3fVqlX7MnNkqmU9v889IhYAnwPenZk/6vR5R2ZmRPT+W6Jzm23ANoCRkZEcHR09k5s/YxD/Ye/m5ae49UB7PwLQ5nxtzgbtztfmbFB3vsPXj/Y3zCRjY2OcbcedrZ7eLRMRz6FT7Ldn5ufL8PHTp1vK98fK+FFg6YSbLyljkqQ50su7ZQLYDhzKzA9NWLQLWF+m1wN3TRh/e3nXzFXAicw81sfMkqQZ9PIa5lXA24ADEbG/jP0lsBX4TERsBL4LvKUs+xKwBhgHfgK8o6+JJUkzmrHcyx9Go8vi1VOsn8ANs8wlSZoFP6EqSRWy3CWpQpa7JFXIcpekClnuklQhy12SKmS5S1KFLHdJqpDlLkkVstwlqUKWuyRVyHKXpApZ7pJUIctdkipkuUtShSx3SaqQ5S5JFbLcJalClrskVchyl6QKWe6SVCHLXZIqZLlLUoUsd0mqkOUuSRWa33QASWra8Ja7B7r9zctPsaHLfRzeunYg9+mRuyRVyHKXpApZ7pJUIctdkipkuUtShSx3SaqQ5S5JFbLcJalClrskVchyl6QKWe6SVKGBlHtEXB0RD0XEeERsGcR9SJK663u5R8Q84KPANcAVwFsj4op+348kqbtBHLm/AhjPzEcz82fATmDdAO5HktRFZGZ/NxjxJuDqzPyTMv824JWZ+c5J620CNpXZlwIP9TXI7FwKPN50iGm0OV+bs0G787U5G5hvNgaV7UWZ+cKpFjR2PffM3AZsa+r+pxMR92bmSNM5umlzvjZng3bna3M2MN9sNJFtEKdljgJLJ8wvKWOSpDkyiHL/D+DyiFgWEecB1wG7BnA/kqQu+n5aJjNPRcQ7gX8B5gGfyMwH+n0/A9bK00UTtDlfm7NBu/O1ORuYbzbmPFvf/6AqSWqen1CVpApZ7pJUoXO63CNiaUTsiYgHI+KBiLixjH8wIo5GxP7ytabBjIcj4kDJcW8ZuzgivhoRD5fvFzWU7aUT9tH+iPhRRLy7qf0XEZ+IiMci4uCEsSn3VXR8pFwi4/6IWNFQvr+NiG+XDF+IiEVlfDginp6wDz/eUL6uj2VEvK/sv4ci4vcayHbHhFyHI2J/GW9i33Xrkuaef5l5zn4BlwEryvTzgf+kc8mEDwLvaTpfyXUYuHTS2N8AW8r0FuCWFuScB/wAeFFT+w94LbACODjTvgLWAF8GArgK2NtQvt8F5pfpWybkG564XoP7b8rHsvw7+RZwPrAMeASYN5fZJi2/FfirBvddty5p7Pl3Th+5Z+axzLyvTP8YOAQsbjZVT9YBO8r0DuDaBrOcthp4JDO/21SAzPw68N+Thrvtq3XAp7LjHmBRRFw21/ky8yuZearM3kPncyGN6LL/ulkH7MzM/8nM7wDjdC49MufZIiKAtwCfHtT9z2SaLmns+XdOl/tEETEMvBzYW4beWV4ufaKp0x5FAl+JiH3lkg0AQ5l5rEz/ABhqJtqzXMez/3G1Zf9121eLge9PWO8Izf9i/2M6R3OnLYuIb0bEv0XEa5oKxdSPZZv232uA45n58ISxxvbdpC5p7PlnuQMRsQD4HPDuzPwR8DHgN4CXAcfovORryqszcwWdq2zeEBGvnbgwO6/xGn0/a3Q+rPZG4LNlqE377xlt2FfdRMT7gVPA7WXoGPDrmfly4CbgnyLiBQ1Ea+VjOclbefaBRWP7boouecZcP//O+XKPiOfQeTBuz8zPA2Tm8cz838z8BfD3DPDl5kwy82j5/hjwhZLl+OmXcOX7Y03lK64B7svM49Cu/Uf3fdWay2RExAbgDcD1pQAopzueKNP76JzT/s25zjbNY9mK/RcR84E/BO44PdbUvpuqS2jw+XdOl3s5V7cdOJSZH5owPvHc1x8AByffdi5ExIUR8fzT03T++HaQzuUc1pfV1gN3NZFvgmcdObVl/xXd9tUu4O3lXQtXAScmvHyeMxFxNfBe4I2Z+ZMJ4y+Mzv+NQES8GLgceLSBfN0ey13AdRFxfkQsK/n+fa7zAa8Hvp2ZR04PNLHvunUJTT7/5vIvym37Al5N52XS/cD+8rUG+EfgQBnfBVzWUL4X03lHwreAB4D3l/FLgN3Aw8C/Ahc3uA8vBJ4AFk4Ya2T/0fkFcwz4OZ1zmBu77Ss671L4KJ2jugPASEP5xumcez39/Pt4WfePymO+H7gP+P2G8nV9LIH3l/33EHDNXGcr458E/nTSuk3su25d0tjzz8sPSFKFzunTMpJUK8tdkipkuUtShSx3SaqQ5S5JFbLcJalClrskVej/ADAYxTtuqs9LAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    5000.000000\n",
              "mean       82.190000\n",
              "std        44.968771\n",
              "min        12.000000\n",
              "25%        45.000000\n",
              "50%        74.000000\n",
              "75%       114.000000\n",
              "max       204.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i96CwCN3QwyW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d1a013f-e954-49ba-fbe2-6b78116b47ee"
      },
      "source": [
        "mean = pd.Series(reviews_len).mean(0)\n",
        "std = pd.Series(reviews_len).std(0)\n",
        "\n",
        "MAX_LEN = int(mean + (2*std))\n",
        "print(MAX_LEN)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGFiTuHXtLdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def populate_tensor(token_list, max_len):\n",
        "  '''\n",
        "  Takes elements inside a list of lists and populates a Torch Tensor\n",
        "  Limits the max # of elements in a row vector to max_len\n",
        "  '''\n",
        "  tensor = torch.zeros(len(token_list) ,max_len, dtype=torch.long)\n",
        "  for i,x in enumerate(token_list):\n",
        "    for j,elem in enumerate(x[:max_len]):\n",
        "      tensor[i,j] = elem\n",
        "  \n",
        "  return tensor"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMFjqqVcZxy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "d06e3e90-8085-4d16-cf40-19e8a9579b41"
      },
      "source": [
        "train_tensor = populate_tensor(train_token, MAX_LEN)\n",
        "\n",
        "print(train_tensor[1])\n",
        "print(train_tensor.dtype)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  27,    8,    2,   86,  301,  119, 4772,   13,    5,  301,    3,  149,\n",
            "          22,   68,  233,  898,    2,  319,   12,    3,   23,   63,  503,    5,\n",
            "         254, 2942,    8,    2,  301,    2,  119,    3,  320,  612,    2, 1079,\n",
            "           6,    1,    1,   90,   14,   35,   25,   69, 1616,   47,    6,  388,\n",
            "           2,  969,    4,    7, 1967,   27,    8,   24,  265,  657,   52,   10,\n",
            "          41,  899,  943,    8,  244, 1679,    4, 1220,  153,  164,  557,    4,\n",
            "         399,  551,    3,  359,   34,   25,   52,   17,   18,   84,   94,    8,\n",
            "         164, 2439,    8,  153,   11,   24,   79,  267,  301, 4772,    3,  171,\n",
            "        1080,   12,   27,    8,    2,  153,  137,    5, 4773, 2076,   51,  838,\n",
            "        1818,    6,   24,  749,   20,   94, 4259,   24,   27, 1260,   43,    9,\n",
            "         969,   10,   12,   38,  142, 1261,    1,  613,   11,   94,    8,    2,\n",
            "         153,   90,    3,  138, 2179,   19,   71,   32,  164, 1364,   22,  826,\n",
            "           3,   50,  122,  944,    2,  371,  154,    7,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGm2W7SaU6VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frac_len = int(len(train_token)*0.8)\n",
        "\n",
        "train_x, valid_x = torch.split(train_tensor, frac_len)\n",
        "train_y, valid_y = torch.split(torch.from_numpy(train_labels), frac_len)\n",
        "\n",
        "train_set = tdata.TensorDataset(train_x, train_y)\n",
        "valid_set = tdata.TensorDataset(valid_x, valid_y)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7-i1jYmzHsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = tdata.DataLoader(train_set, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "valid_loader = tdata.DataLoader(valid_set, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQJPCKGz5uEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "3954c37f-9e7a-4f71-b61b-19878aabd0f3"
      },
      "source": [
        "sample_x, sample_y = next(iter(train_loader))\n",
        "\n",
        "print(f\"Sample input: {sample_x}\")\n",
        "print(f\"Sample input size: {sample_x.shape}\")\n",
        "print(f\"Sample target: {sample_y}\")\n",
        "print(f\"Sample target size: {sample_y.shape}\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input: tensor([[   3,  242,    9,  ...,    0,    0,    0],\n",
            "        [  33,  126,    1,  ...,    0,    0,    0],\n",
            "        [ 883,    3,  381,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [4906,    8,    2,  ...,    0,    0,    0],\n",
            "        [  35,  126,   39,  ...,    0,    0,    0],\n",
            "        [   2, 3343,   10,  ...,    0,    0,    0]])\n",
            "Sample input size: torch.Size([128, 172])\n",
            "Sample target: tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "        0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
            "        1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
            "        1, 1, 0, 1, 0, 1, 1, 0])\n",
            "Sample target size: torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySObaJ-808bY",
        "colab_type": "text"
      },
      "source": [
        "##Working with Custom RNN / LSTM models\n",
        "This is the crux of the workshop, using the class of NNs called RNNs. The same concept can be applied to GRUs with a slight change to the parameters; \n",
        "\n",
        "RNN layers will output the (output state,hidden state) tuple.\n",
        "\n",
        "Output is the concat of hidden states from every time step, hidden state is the final hidden state\n",
        "\n",
        "Notice for LSTMs, the implementation allows for multiple layers to be stacked on top of another (More on the lecture)\n",
        "and a probability for the forget gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDZ9BF2p08Kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super(CustomRNN, self).__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim) #Add num_layers, bidirectional, dropout etc. parameters to further experiment!\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "      \n",
        "    def forward(self, token):\n",
        "      print(token.shape) #[128,172]\n",
        "      token = token.permute(1,0)\n",
        "      print(token.shape) #[172,128]\n",
        "      embedded = self.embed(token)\n",
        "      print(embedded.shape) #[172,128,6000]\n",
        "      rnn_out, hidden = self.rnn(embedded)\n",
        "      print(hidden.shape) #[1,128,256]\n",
        "      hidden = torch.squeeze(hidden, 0)\n",
        "      linear_out = self.fc(hidden) #input[128,256] output [128,1]\n",
        "      print(linear_out.shape)\n",
        "      out_long = self.sig(linear_out)\n",
        "      out_long = torch.squeeze(out_long,1)\n",
        "      #output = out_long.float()\n",
        "      #print(output.shape)\n",
        "      #print(output.dtype)\n",
        "      #return output\n",
        "      return out_long"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu_56odxtguY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Instatiating the GPU\n",
        "torch.cuda.empty_cache()\n",
        "cudnn.benchmark = False  # Optimise for hardware\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpzNZfiq6xqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "input_dim = len(word2idx) + 2\n",
        "embedding_dim = 6000 #Size of dense word vectors, a hyperparam\n",
        "hidden_dim = 256 #Size of the hidden states, generally linearly dependent on the size of the input data, complexity of task; A key hyperparameter in RNNs\n",
        "output_dim = 1 #2 classes of output values between 0 and 1\n",
        "\n",
        "model = CustomRNN(input_dim = input_dim, embedding_dim = embedding_dim, hidden_dim = hidden_dim, output_dim = output_dim)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u01Ga2ePNAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "512824e5-8872-4333-e1cb-8b6953448b32"
      },
      "source": [
        "model"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomRNN(\n",
              "  (embed): Embedding(5002, 6000)\n",
              "  (rnn): RNN(6000, 256)\n",
              "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPD3ezm9OZ8t",
        "colab_type": "text"
      },
      "source": [
        "# The Training & Validation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e44pHzWbj00h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, loss_fn, optimizer, device):\n",
        "    model.train() # puts the model in training mode\n",
        "    running_loss = 0\n",
        "\n",
        "    for tokens, labels in iterator: # loops through training data\n",
        "      tokens, labels = tokens.to(device), labels.to(device)\n",
        "      optimizer.zero_grad() # clear the gradients in model parameters\n",
        "      outputs = model(tokens)\n",
        "\n",
        "      loss = loss_fn(outputs.long(), labels) # calculate loss\n",
        "\n",
        "      loss.backward() # calculates gradient w.r.t to loss for all parameters in model that have requires_grad=True\n",
        "      optimizer.step() # iterate over all parameters in the model with requires_grad=True and update their weights.\n",
        "\n",
        "      running_loss += loss.item() # sum total loss in current epoch for print later\n",
        "\n",
        "    return running_loss/len(iterator) # returns the total training loss for the epoch"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2QY58AvqJDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad() #Function decorator, wraps validation inside no_grad\n",
        "def validation(model, iterator, loss_fn, device):\n",
        "    model.eval() # puts the model in eval mode, tells embedded layers etc to behave in eval mode\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for tokens, labels in iterator:\n",
        "      tokens, labels = tokens.to(device), labels.to(device)\n",
        "      outputs= model(tokens) # passes image to the model, and gets a ouput which is the class probability prediction\n",
        "\n",
        "      val_loss = loss_fn(outputs.long(), labels) # calculates val_loss from model predictions and true labels\n",
        "      running_loss += val_loss.item()\n",
        "\n",
        "      outputs = outputs.round()\n",
        "      total += len(labels)\n",
        "\n",
        "      correct += (outputs == labels).sum().item() #compare the output sentiment to labels\n",
        "        \n",
        "    return running_loss/len(iterator), correct/total # return loss value, accuracy"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xedFUaJCMNMR",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "Try out different hidden state sizes and layers and observe the time taken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL8voSz-4fKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_epoch = 100\n",
        "for epoch in range(total_epoch):\n",
        "  start_time = time.clock()\n",
        "  train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "  val_loss, accuracy = validation(model, valid_loader, criterion, device)\n",
        "  end_time = time.clock()\n",
        "  print(f\"Epoch: {epoch+1}/{total_epoch}, Training Loss: {train_loss}, Val Loss: {val_loss}, Val Accuracy: {accuracy}, Time taken: {end_time-start_time}\")\n",
        "  print('-' * 20)\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}